{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vjmaurina/Projeto_Imersao_Avaliacao/blob/main/Projeto_Alura_Imersao02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Instala a biblioteca google.generativeai, que fornece acesso à API de IA generativa do Google.**"
      ],
      "metadata": {
        "id": "bt6KZnWkJv_s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JbXe7Oodc5dP"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q google.generativeai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Instala a biblioteca chromadb, que fornece uma interface para criar e consultar bancos de dados de embeddings.**"
      ],
      "metadata": {
        "id": "1g3E50wNKFWf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNCv-cJPLOZ2"
      },
      "outputs": [],
      "source": [
        "!pip install -q chromadb"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importa as bibliotecas necessárias para processamento de texto, criação de banco de dados de embeddings e manipulação de dados.**"
      ],
      "metadata": {
        "id": "y1bdUCsXKLdR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "muuhsDmmKdHi"
      },
      "outputs": [],
      "source": [
        "import textwrap\n",
        "import chromadb\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import google.generativeai as genai\n",
        "import google.ai.generativelanguage as glm\n",
        "\n",
        "Importa as bibliotecas google.generativeai e google.ai.generativelanguage, que fornecem acesso à API de IA generativa do Google.\n",
        "from google.colab import userdata\n",
        "\n",
        "from IPython.display import Markdown\n",
        "from chromadb import Documents, EmbeddingFunction, Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lista os modelos de IA generativa disponíveis que suportam o método de geração embedContent.**"
      ],
      "metadata": {
        "id": "rbsGj82VM-G6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Km5d13_FS2Q_"
      },
      "outputs": [],
      "source": [
        "for m in genai.list_models():\n",
        "  if 'embedContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define três documentos de texto e os armazena em uma lista.**"
      ],
      "metadata": {
        "id": "Sx9EpWO6ND34"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8nsbhFJKmG-"
      },
      "outputs": [],
      "source": [
        "DOCUMENT1 = \"Operando o sistema de controle climático Seu Googlecar tem um sistema de controle climático que permite ajustar a temperatura e o fluxo de ar no carro. Para operar o sistema de controle climático, use os botões e botões localizados no console central. Temperatura: O botão de temperatura controla a temperatura dentro do carro. Gire o botão no sentido horário para aumentar a temperatura ou no sentido anti-horário para diminuir a temperatura. Fluxo de ar: O botão de fluxo de ar controla a quantidade de fluxo de ar dentro do carro. Gire o botão no sentido horário para aumentar o fluxo de ar ou no sentido anti-horário para diminuir o fluxo de ar. Velocidade do ventilador: O botão de velocidade do ventilador controla a velocidade do ventilador. Gire o botão no sentido horário para aumentar a velocidade do ventilador ou no sentido anti-horário para diminuir a velocidade do ventilador. Modo: O botão de modo permite selecionar o modo desejado. Os modos disponíveis são: Automático: O carro ajustará automaticamente a temperatura e o fluxo de ar para manter um nível confortável. Frio: O carro soprará ar frio para dentro do carro. Aquecimento: O carro soprará ar quente para dentro do carro. Descongelamento: O carro soprará ar quente no para-brisa para descongelá-lo.\"\n",
        "DOCUMENT2 = \"Seu Googlecar tem uma grande tela sensível ao toque que fornece acesso a uma variedade de recursos, incluindo navegação, entretenimento e controle climático. Para usar a tela sensível ao toque, basta tocar no ícone desejado. Por exemplo, você pode tocar no ícone Navegação para obter instruções para o seu destino ou tocar no ícone Música para tocar suas músicas favoritas.\"\n",
        "DOCUMENT3 = \"Mudando de marcha Seu Googlecar tem uma transmissão automática. Para mudar de marcha, basta mover a alavanca de câmbio para a posição desejada. Estacionamento: Esta posição é usada quando você está estacionado. As rodas estão travadas e o carro não pode se mover. Ré: Esta posição é usada para dar ré. Neutro: Esta posição é usada quando você está parado em um semáforo ou no trânsito. O carro não está engatado e não se moverá a menos que você pressione o pedal do acelerador. Dirigir: Esta posição é usada para dirigir para frente. Baixo: Esta posição é usada para dirigir na neve ou em outras condições escorregadias.\"\n",
        "documents = [DOCUMENT1, DOCUMENT2, DOCUMENT3]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define uma classe personalizada GeminiEmbeddingFunction que herda da classe EmbeddingFunction da biblioteca chromadb. Esta classe é usada para gerar embeddings para documentos de texto usando o modelo de incorporação Gemini.**"
      ],
      "metadata": {
        "id": "TQXpcGsDNJLg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mF7Uu1kCQsT0"
      },
      "outputs": [],
      "source": [
        "class GeminiEmbeddingFunction(EmbeddingFunction):\n",
        "  def __call__(self, input: Documents) -> Embeddings:\n",
        "    model = 'models/embedding-001'\n",
        "    title = \"Custom query\"\n",
        "    return genai.embed_content(model=model,\n",
        "                                content=input,\n",
        "                                task_type=\"retrieval_document\",\n",
        "                                title=title)[\"embedding\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define uma função create_chroma_db que cria um banco de dados de embeddings usando a biblioteca chromadb. A função leva uma lista de documentos de texto e um nome para o banco de dados como parâmetros.**"
      ],
      "metadata": {
        "id": "Qb0m7pYaNPiA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OITXgxZlLoXU"
      },
      "outputs": [],
      "source": [
        "def create_chroma_db(documents, name):\n",
        "  chroma_client = chromadb.Client()\n",
        "  db = chroma_client.create_collection(name=name, embedding_function=GeminiEmbeddingFunction())\n",
        "\n",
        "  for i, d in enumerate(documents):\n",
        "    db.add(\n",
        "      documents=d,\n",
        "      ids=str(i)\n",
        "    )\n",
        "  return db"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cria um banco de dados de embeddings chamado \"googlecarsdatabase\" usando a função create_chroma_db e os documentos de texto definidos anteriormente.**"
      ],
      "metadata": {
        "id": "XuqMZ-bXNTzf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJ3Fq0yzL10B"
      },
      "outputs": [],
      "source": [
        "db = create_chroma_db(documents, \"googlecarsdatabase\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exibe as primeiras três linhas do banco de dados de embeddings como um DataFrame do Pandas.**"
      ],
      "metadata": {
        "id": "kdltq6YINX9-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQ9PHUL_l-hf"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(db.peek(3))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define uma função get_relevant_passage que leva uma consulta e um banco de dados de embeddings como parâmetros. A função retorna a passagem mais relevante do banco de dados para a consulta.**"
      ],
      "metadata": {
        "id": "Fz2Hu5_sNf9_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQdJMbTSLtKE"
      },
      "outputs": [],
      "source": [
        "def get_relevant_passage(query, db):\n",
        "  passage = db.query(query_texts=[query], n_results=1)['documents'][0][0]\n",
        "  return passage"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Recupera a passagem mais relevante do banco de dados de embeddings para a consulta \"touch screen features\" e a exibe como texto formatado.**"
      ],
      "metadata": {
        "id": "yQuCxIxmNl5f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWYXXKJ6t6Hy"
      },
      "outputs": [],
      "source": [
        "passage = get_relevant_passage(\"touch screen features\", db)\n",
        "Markdown(passage)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define uma função make_prompt que leva uma consulta e uma passagem relevante como parâmetros. A função retorna um prompt de geração de linguagem natural que pode ser usado para gerar uma resposta à consulta usando a passagem relevante como contexto.**"
      ],
      "metadata": {
        "id": "oWdP4SiYNwgS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qkhu4iazLy3G"
      },
      "outputs": [],
      "source": [
        "def make_prompt(query, relevant_passage):\n",
        "  escaped = relevant_passage.replace(\"'\", \"\").replace('\"', \"\").replace(\"\\n\", \" \")\n",
        "  prompt = (\"\"\"Você é um bot útil e informativo que responde perguntas usando texto da passagem de referência incluída abaixo.\n",
        "  Certifique-se de responder em uma frase completa, sendo abrangente, incluindo todas as informações relevantes.\n",
        "  No entanto, você está falando com um público não técnico, por isso certifique-se de quebrar conceitos complicados e\n",
        "  um tom amigável e conversível.\n",
        "  Se a passagem é irrelevante para a resposta, você pode ignorá-la.\n",
        "  QUESTION: '{query}'\n",
        "  PASSAGE: '{relevant_passage}'\n",
        "\n",
        "    ANSWER:\n",
        "  \"\"\").format(query=query, relevant_passage=escaped)\n",
        "\n",
        "  return prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cria um prompt de geração de linguagem natural para a consulta \"Como você usa a tela sensível ao toque no carro do Google?\" usando a passagem relevante recuperada anteriormente.**"
      ],
      "metadata": {
        "id": "X6rK3_UqN7vP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6_Y-GOymaXu"
      },
      "outputs": [],
      "source": [
        "query = \"Como você usa a tela sensível ao toque no carro do Google?\"\n",
        "prompt = make_prompt(query, passage)\n",
        "Markdown(prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gera uma resposta à consulta usando o modelo de geração de linguagem natural Gemini-pro e o prompt criado anteriormente. A resposta é exibida como texto formatado.**"
      ],
      "metadata": {
        "id": "-PYyxeY2OBrY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EwfyxFM6Giy9"
      },
      "outputs": [],
      "source": [
        "model = genai.GenerativeModel('gemini-pro')\n",
        "answer = model.generate_content(prompt)\n",
        "Markdown(answer.text)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}