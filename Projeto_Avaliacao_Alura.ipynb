{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM5PeZ8F3FjvUbzP66t/OQz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vjmaurina/Projeto_Imersao_Avaliacao/blob/main/Projeto_Avaliacao_Alura.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q google-generativeai"
      ],
      "metadata": {
        "id": "tHapFUQmXAx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get('SECRET_KEY')\n",
        "genai.configure(api_key=api_key)\n",
        "\n",
        "model_embedContent = \"models/embedding-001\"\n",
        "generation_config = {\"temperature\": 0,\"candidate_count\": 1}"
      ],
      "metadata": {
        "id": "kNYNPCIfW5qw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregando dados do CSV\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/vjmaurina/Projeto_Imersao_Avaliacao/main/dataset_reg10.csv')\n",
        "\n",
        "# Convertendo o DataFrame em uma lista de dicionários\n",
        "documents = df.to_dict('records')"
      ],
      "metadata": {
        "id": "CRL5QnZEYBh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(documents)"
      ],
      "metadata": {
        "id": "4dyYy3j6fZfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "IWEtB392bsWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def embed_fn(title, text):\n",
        "    return genai.embed_content(model=model_embedContent,\n",
        "                               content=text,\n",
        "                               title=title,\n",
        "                               task_type=\"RETRIEVAL_DOCUMENT\")[\"embedding\"]"
      ],
      "metadata": {
        "id": "N6d6q-z0YMaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Embeddings\"] = df.apply(lambda row: embed_fn(row[\"ID_Pedido\"], row[\"Data_Pedido\"]), axis=1)\n",
        "df"
      ],
      "metadata": {
        "id": "sHfIgHukcDHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gerar_e_buscar_consulta(consulta, base, model):\n",
        "    embedding_da_consulta = genai.embed_content(model=model,\n",
        "                                               content=consulta,\n",
        "                                               task_type=\"RETRIEVAL_QUERY\")[\"embedding\"]\n",
        "    produtos_escalares = np.dot(np.stack(df[\"Embeddings\"]), embedding_da_consulta)\n",
        "    indice = np.argmax(produtos_escalares)\n",
        "    return df.iloc[indice][\"Data_Pedido\"]"
      ],
      "metadata": {
        "id": "DUigQ_ZeYdoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "consulta = \"Qual é a Data do Pedido US-2016-108966?\"\n",
        "trecho = gerar_e_buscar_consulta(consulta, df, model_embedContent)\n",
        "prompt = f\"Reescreva esse texto apenas informando somente **Data do Pedido é:**: {trecho}\"\n",
        "model_2 = genai.GenerativeModel(\"gemini-1.0-pro\",\n",
        "                                generation_config=generation_config)\n",
        "response = model_2.generate_content(prompt)\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "WaHUCnGGYng8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}